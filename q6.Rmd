---
title: "Question 6"
author: "Karen Abraham"
date: "12-09-2021"
output:
  html_document:
    df_print: paged
---
# Question 6: What kind of segmentation can be used to categorize actors?

## Loading Data and Libraries

```{r}
#clear environment
rm(list = ls())
options(warn=-1)

#loading libraries (must be installed before where necessary)
library(readr)
library(dplyr)
library(ggplot2)
#Libraries for clustering
library(clustertend) #for hopkins stat
library(factoextra) #for Elbow method: TSS vs k
library(stats) #for kmeans clustering
#Libraries for word cloud
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)

#Loading the dataset
ged211 <- read_csv("ged211.csv")
head(ged211)
```

#Transformation

In order to perform a cluster analysis of the conflicts, the data needs to be transformed
I will create a table with 
Conflict Name, # of dyads, total deaths, active years, active countries

```{r}
#Transformation
over0 <- subset(ged211, best>0 & type_of_violence!=3)
over0 <- cbind.data.frame(over0$conflict_name,over0$dyad_new_id,over0$best,over0$year,over0$country)
colnames(over0) <- c("conflict_name","dyad","best","year","country")

confl <- over0 %>%
  distinct(conflict_name)


#total deaths
sums <- aggregate(over0$best, list(over0$conflict_name), sum)
colnames(sums) <- c("conflict_name","total_deaths")

confl <- full_join(confl, sums, by = "conflict_name")

#active years
years <- aggregate(over0$year, list(over0$conflict_name), FUN=function(x) length(unique(x)))
colnames(years) <- c("conflict_name","active_years")

confl <- full_join(confl, years, by = "conflict_name")

#active countries
cntrs <- aggregate(over0$country, list(over0$conflict_name), FUN=function(x) length(unique(x)))
colnames(cntrs) <- c("conflict_name","active_countries")

confl <- full_join(confl, cntrs, by = "conflict_name")

#active dyads
dyd <- aggregate(over0$dyad, list(over0$conflict_name), FUN=function(x) length(unique(x)))
colnames(dyd) <- c("conflict_name","dyads")

confl <- full_join(confl, dyd, by = "conflict_name")


#confl <- confl %>% select(-total_deaths.y)

head(confl)
```

```{r}
#Normalizing values
normalize <- function(x) {
    (x - min(x)) / (max(x) - min(x))
  }
clust_df <- confl
clust_df[2:5] <- as.data.frame(lapply(confl[2:5], normalize))

head(clust_df)
```
```{r}
hopkins(clust_df[2:5], n=25)
get_clust_tendency(clust_df[2:5], n=25) #1-H is hopkins stat
# Lawson and Jurs (1990) and Banerjee & Dave (2004) explains that you may expect 3 different results: 1) H = 0.5 (the dataset reveals no clustering structure) " in the formula, W always refers to the real data, and it is in the denominator) 2) H close to 1.0, a significant evidence that the data might be cluster-able. 3) H is close to 0, in this case the test is indecisive (data are neither clustered nor random)
```


```{r}
#Number of clusters
#using original ds
dist.eucl <- dist(clust_df[2:5], method = "euclidean")
#optimal number of clusters
factoextra::fviz_nbclust(clust_df[2:5], kmeans, method = "wss") +ggplot2::geom_vline(xintercept = 3)
```


Now we can start the cluster analysis

```{r}
# Compute k-means with k = 4
set.seed(1)
km.res <- kmeans(clust_df[2:5], 3, nstart = 25)
print(km.res)
```

```{r}
km.unnrm <- km.res$center

#Unnormalizing values
km.unnrm[,1] <- km.res$centers[,1] * (max(confl$total_deaths)-min(confl$total_deaths))  + min(confl$total_deaths)
km.unnrm[,2] <- km.res$centers[,2] * (max(confl$active_years)-min(confl$active_years))  + min(confl$active_years)
km.unnrm[,3] <- km.res$centers[,3] * (max(confl$active_countries)-min(confl$active_countries))  + min(confl$active_countries)
km.unnrm[,4] <- km.res$centers[,4] * (max(confl$dyads)-min(confl$dyads))  + min(confl$dyads)

km.unnrm
```

```{r}
dd <- cbind(clust_df, cluster = km.res$cluster)
head(dd)
```

```{r}
km.res$size
km.res$centers

```




```{r}
plot(dd$total_deaths, dd$active_years,
     pch = 19,
     col = factor(dd$cluster),
     main="Conflict Clusters Deaths-Years",
     xlab="Total Deaths in Conflict",
     ylab="Total Years in Conflict")
```
```{r}
plot(dd$active_years, dd$active_countries,
     pch = 19,
     col = factor(dd$cluster),
     main="Conflict Clusters Years-Countries",
     xlab="Total Years in Conflict",
     ylab="Total Countries in Conflict")
```
```{r}
plot(dd$dyads,dd$active_years, 
     pch = 19,
     col = factor(dd$cluster),
     main="Conflict Clusters: Dyads",
     xlab="# of Dyads in Conflict",
     ylab="Total Years in Conflict")
```
```{r}
subset(dd,cluster==3)
```

```{r}
subset(dd,cluster==2)
```

```{r}
subset(dd,cluster==1)
```
```{r}
#https://ggplot2-book.org/maps.html
ged_cl <- subset(ged211, ged211$year> 2009)
ged_cl <- full_join(ged_cl, dd, by = "conflict_name")

#blank world map
world <- map_data("world")
map <- ggplot() + geom_polygon(data = world, aes(x=long, y = lat,group = group),fill=NA,color="grey")

#factor the type of violence column
ged_cl$cluster <- as.factor(ged_cl$cluster)

#add points to map
map + geom_point(data = ged_cl, aes(x = longitude, y = latitude, col = cluster), size = 0.05) +
  ggtitle("Map of Instances by Clusters") +
  ylab("Latitude") + 
  xlab("Longitude")
```

```{r}
ttl <- ged_cl%>%
  dplyr::group_by(cluster,year) %>%
  dplyr::summarize(total = sum(best))

ttl <- subset(ttl, ttl$year>2009)
ttl %>%
  ggplot( aes(x=year, y=total, col=cluster)) +
  geom_line() +
  ggtitle("Organized Violence by Cluster 2010-2020") +
  xlab("Year")+
  ylab("Total Deaths")
```

```{r}
km.res$betweenss
km.res$totss
km.res$tot.withinss

km.res$betweenss / km.res$totss * 100
```

Word cloud generation algorithm taken directly from:

Rul, C. V. (2019, October 20). How to Generate Word Clouds in R. Retrieved from https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a

```{r}
#CLUSTER 1
#Create a vector containing only the text
text <- subset(dd$conflict_name, dd$cluster==1)
# Create a corpus  
docs <- Corpus(VectorSource(text))


docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))


dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)

set.seed(132)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=100, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```

```{r}
#Create a vector containing only the text
text <- subset(dd$conflict_name, dd$cluster==2)
# Create a corpus  
docs <- Corpus(VectorSource(text))


docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))


dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)

set.seed(123)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=100, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```

```{r}
#Create a vector containing only the text
text <- subset(dd$conflict_name, dd$cluster==3)
# Create a corpus  
docs <- Corpus(VectorSource(text))


docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))


dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)

set.seed(123)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,           max.words=100, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```

# Libraries Used
### Documentation and functionality
readr: https://www.rdocumentation.org/packages/readr/versions/1.3.1
dplyr: https://www.rdocumentation.org/packages/dplyr/versions/0.7.8
ggplot2: https://ggplot2.tidyverse.org/

#Libraries for clustering
clustertend (Hopkins statistic): https://rdrr.io/cran/clustertend/
factoextra (Elbow method): https://www.rdocumentation.org/packages/factoextra/versions/1.0.7
stats (kmeans Clustering): https://www.rdocumentation.org/packages/stats/versions/3.6.2

#Libraries for word cloud
wordcloud: https://www.rdocumentation.org/packages/wordcloud/versions/2.6
RColorBrewer: https://cran.r-project.org/web/packages/RColorBrewer/index.html
wordcloud2: https://cran.r-project.org/web/packages/wordcloud2/index.html
tm: https://cran.r-project.org/web/packages/tm/index.html


# Sources Used
### For the word clouds:
Rul, C. V. (2019, October 20). How to Generate Word Clouds in R. Retrieved from https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a